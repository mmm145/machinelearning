{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c33da8-3027-44b6-9fa7-8e496105b38a",
   "metadata": {},
   "source": [
    "# Neural Network ( super vised learning ) \n",
    "\n",
    "\n",
    "## Neural network architectures.\n",
    "\n",
    "### Hyperparameters and cost functions to use for neural networks.\n",
    "\n",
    "### How to calculate gradients of the loss w.r.t. all parameters in the neural network.\n",
    "\n",
    "### How to initialize the weights and regularize the network in ways to improve the training of the network.\n",
    "\n",
    "## motivation \n",
    "\n",
    "- if the data is not lineary separable\n",
    "\n",
    "\n",
    "- feature augumentaion/ adding non linearity\n",
    "  - $(x1, x2) ->(x1^2, x2^2, x1x2, x1,x2)$\n",
    "  - kernel trick -> SVM\n",
    "- use more and more linear decision boundary\n",
    "  - doing a lot of linear connection -> deep neural net\n",
    "\n",
    "\n",
    "## activation function \n",
    "\n",
    "- without activation function > deep neural net just do the linear transformation on data.\n",
    "  - $W1W2x= Wx$\n",
    "\n",
    "## type of nn\n",
    "\n",
    "- CNN\n",
    "- RNN\n",
    "\n",
    "## purpose \n",
    "\n",
    "- wanna know a non-linear decesion boundary\n",
    "  - by combining the linear decesion boundary\n",
    "\n",
    "\n",
    "\n",
    "## layers of NN \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## hyper parameter of mlp / fully connected neural network.\n",
    "\n",
    "## back propagation \n",
    "\n",
    "- chain rule\n",
    "\n",
    "\n",
    "in order to update the parameters, the gradient of loss with regard to the parameter is necessary\n",
    "but\n",
    "in NN, some parameters are not connected to the output\n",
    "\n",
    "how to get the gradient with regard to the parameter??\n",
    "\n",
    "=> you wanna use back propagation. \n",
    "\n",
    "**back propagation**\n",
    "\n",
    "- propagate the gradient from the end to the beginning of the neural network\n",
    "- make it easy to calculate the gradient. \n",
    "\n",
    "\n",
    "## inductive bias \n",
    "\n",
    "- the assumption each model have so that the model works well\n",
    "  - conditional independent and naive bayse theorem for naive bayse classifier.\n",
    "  - spliting data hierarchically for deceion tree\n",
    "  - linearly separable data in feature space for logistic regression.\n",
    " \n",
    "  -  In CNN, it is composed of local integration, and it should merge the prior local feature layers.\n",
    " \n",
    "**benefits from inductive bias**\n",
    "\n",
    "- effective computation\n",
    "  - Inductive bias limit hypothesis space that should be trained, which makes it easier to calculate.\n",
    " \n",
    "- small data set for learning\n",
    "  - size of data set can be small thanks to the inductive bias\n",
    "\n",
    "- more effective generalization\n",
    "  - Inductive bias provides the more accurate prediction on unknown data, especially the unknown data can be created based on Inductive bias.\n",
    " \n",
    "- prior integration of knowledge.\n",
    "  - Inductive bias can include the knowledge that is unique to the specific task and filed, which leads to the more accurate prediction and efficitnet training.\n",
    "\n",
    "- easy interpretation\n",
    "  - like decision tree/ linear regression...\n",
    "\n",
    "### inductive bias and LLM\n",
    "\n",
    "LLM is usually used by transformers, which means it has a few inductive bias.\n",
    "=> LLM needs a large amount of data to predict accurately enough. \n",
    "\n",
    "the larger the data set, the better transformer performs,\n",
    "=> when the data set is large, transformer is the best choice. \n",
    "\n",
    ">>> from data, we should come up with proper inductive ia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
