{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6b0015-bfef-42e9-a1aa-92389d2da6a6",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "- image classification\n",
    "- special case for the fully connected neural networks.\n",
    "- the number of weights is independent from input size\n",
    "- the architecture plays a important role in CNN\n",
    "- deeper and wider == more feature map\n",
    "  - better performacne.\n",
    "  - thanks to the residual learning\n",
    "  - but\n",
    "  - causing the sparse == learning some common feature in waste\n",
    "    - inception layer solve this problem. \n",
    "\n",
    "## 1. inductive bias of cnn\n",
    "\n",
    "**locality**\n",
    "\n",
    "- near by pixcels - tend to be similar and vary in particular way \n",
    "- near by patches - similar characteristic and particular way of combining them\n",
    "- near by regsions - tend to be found in particular arrangement.\n",
    "\n",
    "**Translation Invariance**\n",
    "\n",
    "- let's say, the image has a dog in it.\n",
    "- the location of pixcels that creates dog does not matter. How they are aranged with each othr in image matter.\n",
    "\n",
    "**inductive bias**\n",
    "\n",
    "- input is restricted to regsions < locality\n",
    "- same filter can be used throughtout the image <- translation invariance. \n",
    "\n",
    "## 2. Component of CNN \n",
    "\n",
    "- Filter / kernel\n",
    "  - matrix of weight to apply for image data\n",
    "  - to detect the pattern and strengthen the features of area.\n",
    "  - the size of filter\n",
    " \n",
    "  -  applied to all input channels \n",
    "- Stride\n",
    "  - how much nubmers about filter moving\n",
    "- Input channel\n",
    "  - the number of channels in the input.\n",
    "- Output channel\n",
    "  - The number of filters applied\n",
    "- Padding\n",
    "  - adding zeros to the edge of inputs so that filter can detect the boundary.\n",
    " \n",
    "### Output size \n",
    "\n",
    "(width or height - kernel size + 2 * padding)/stride + 1 \n",
    "\n",
    "- kernel size = nrow or ncol\n",
    "- padding can be two \n",
    "\n",
    "## 3. Layers of CNN\n",
    "- convolutional\n",
    "  - filter / kernel\n",
    "  - stride\n",
    "  - \n",
    "  - travers the input X and scan it with filter/kernel K and get the output\n",
    "  - $(X, k)_{i,j} = \\sum \\sum X_{i+p,j+q}K_{p,q}$\n",
    "- pooling\n",
    "  - reduce the dimension of data.\n",
    " \n",
    "  -  max pooling\n",
    "  -  average pooling\n",
    "- batch normalization layers.\n",
    "  - https://www.geeksforgeeks.org/what-is-batch-normalization-in-cnn/ (I wanna read this 2/2 )\n",
    "- fully connected\n",
    "  - classification based on feature you get from previous layers.\n",
    "- drop out\n",
    "\n",
    "## 4. activation function of CNN\n",
    "\n",
    "- Linear or Identity Activation Function.\n",
    "- Non-linear Activation Function.\n",
    "- Sigmoid or Logistic Activation Function.\n",
    "- Tanh or hyperbolic tangent Activation Function.\n",
    "- ReLU (Rectified Linear Unit) Activation Function.\n",
    "- Leaky ReLU.\n",
    "\n",
    "## 5. hyper parameters of CNN\n",
    "\n",
    "\n",
    "### 5.1 in convolutional layer \n",
    "- filter / kernel\n",
    "  - the size\n",
    "  - the values / patterns\n",
    "- stride\n",
    "  - the size of strides. \n",
    "\n",
    "### 5.2 \n",
    "- padding\n",
    "- activation function\n",
    "- optimization method\n",
    "\n",
    "\n",
    "## 6. the number of parameters \n",
    "\n",
    "### 6.1 convolutional layer \n",
    "\n",
    "- parameters = ((width of kernel) * (height of kernel) * (number of input channel) + 1) * (number of filter == number of output channel)\n",
    "\n",
    "### 6.2 fully connected layer\n",
    "\n",
    "\n",
    "## 7. back propagation \n",
    "\n",
    "### 7.1 activation function \n",
    "\n",
    "### 7.2 Convolutional layer.\n",
    "\n",
    "### 7.3 pooling layer\n",
    "\n",
    "- down sampling while maintain the main feature\n",
    "- hyper parameter\n",
    "  - size of pooling filter\n",
    "  - type of pooling layer\n",
    "  - stride\n",
    "    - the number of pixcels the pooling layer moves\n",
    "\n",
    "**max pooling**\n",
    "\n",
    "- get the max value from m*n filter\n",
    "\n",
    "**mean pooling**\n",
    "\n",
    "##  CNN for classification \n",
    "\n",
    "- LeNet\n",
    "- AlexNet\n",
    "  - mean nomaliztion for input\n",
    "    - subtract mean image over training set from each data\n",
    "  - use ReLU for non-linearity.\n",
    "    - at the output of every\n",
    "      - convolutional\n",
    "      - fully-connected.\n",
    "  - regularization\n",
    "    - data augumentation\n",
    "      - spatial augumentation\n",
    "        - Image translation & horizontal reflection\n",
    "          - shift image within small range.\n",
    "          - flip images horizontally. \n",
    "        - random 224 * 224 cropping\n",
    "          - resize the shortest image so that shortest size is 256.\n",
    "          - extract the random 224 * 224 patch\n",
    "          - horizontal reflection.\n",
    "        - test-time augumentation. \n",
    "      - color augumentation\n",
    "        - apply PCA to RGB color\n",
    "    - drop out\n",
    "      - drop out with probability = 0.5\n",
    " - optimization\n",
    "   - SGD with momentum and weight decay.\n",
    "     - Batch size: 128, momentum: 0.9\n",
    "     - Learning rate initialized to 0.01, manually decreased when validation error stopped improving.\n",
    "     - L2 weight decay: 0.0005\n",
    "\n",
    "- ZFNet\n",
    "  - They introduced the deconvnet, which maps the output activations back\n",
    "to input pixels. This enables a visualization of features being captured\n",
    "by the convnets.\n",
    "  - With this, they made optimizations to AlexNet.\n",
    " \n",
    "  -  the difference between AlexNet and ZFNet\n",
    "    - the first conv layer\n",
    "      - filter\n",
    "        - 7 * 7\n",
    "      - stride\n",
    "        - 2\n",
    "    - the 3rd, 4th, 5th conv layer\n",
    "      - 512, 1024 and 512 filters.  \n",
    "\n",
    "\n",
    "- VGG\n",
    "  - focus on small convolutional filter\n",
    "  - extend depth\n",
    "    - the deeper the model get, the more nonlinearity it can capture.\n",
    "  - potential con of using small filter and more layers in VGG net\n",
    "    - higher computational cost\n",
    "    - vanishing gradient problem\n",
    "      - activation function\n",
    "      - how to initialize\n",
    "    - overfitting on small data set.\n",
    "      - the more layer the model has, the better the model can remember the train data instead of generalizing them.\n",
    "      - requires the regularization methods.\n",
    "- GoogLeNet\n",
    "  - the problem of AlexNet, VGG net\n",
    "    - the more layer the model has, the more features the model  can not use. \n",
    "  - inception net\n",
    "    - 1 * 1 * F\n",
    "    - to reduce the depth of feature map.\n",
    "      - to reduce the sparse of the feature, which leads to take more computational time and memory.\n",
    "     \n",
    "  - total 22 layers.\n",
    "  - the concern of inception layer.\n",
    "    - many hyper parameter < many convolutional layer with different size of kernel and depth.\n",
    "   \n",
    "  - the other detail\n",
    "    - SGD with 0.9 momentum\n",
    "    - decrease learning rate by 4% every 8 epochs.\n",
    "    - image size patches from 8 to 100% of the area, having aspect ratio 3 * 4 or 4 * 3. used 144 crops per image.\n",
    "   \n",
    "    -  12 layers less than AlexNet but better performacne than AlexNet \n",
    "- ResNet\n",
    "  - deal with degradetation\n",
    "  - with redual learning\n",
    "    - y = x + F(x)\n",
    "    - unline traditional y = h(x)\n",
    "    - thans to this\n",
    "    - when parameter of F(x) does not update the value\n",
    "      - y = x - identity mapping.\n",
    "     \n",
    "  - network architecture\n",
    "    - based on VGG Net\n",
    "    - and also\n",
    "    - usiing inception layer\n",
    "   \n",
    "    -  when feature size -> * 1/2\n",
    "    -  the feature map -> * 2\n",
    "    -  so that the computational comoplexity will be the same\n",
    "   \n",
    "    -   output\n",
    "      - average pooling\n",
    "      - FC 100 layers\n",
    "      - soft max\n",
    "   \n",
    "    -  other detail\n",
    "      - data augmentation\n",
    "        - image scaling\n",
    "        -  different crops\n",
    "           - for avoding overfitting\n",
    "           -  the model can learn the varisous feature instead of memorizing the image.\n",
    "        - SGD with 0.9 momentum and mini batch size 512\n",
    "        - learning rate starts with 0.1\n",
    "          - then decrease based on the order of magnitude\n",
    "          - when the error reaches the plateus.\n",
    "        - do not use dropout.\n",
    "    - for deeper network\n",
    "      - use an idea similar to inception\n",
    "\n",
    "- Fractal neural network.\n",
    "  - \n",
    "- Inception v4\n",
    "- DenseNet\n",
    "\n",
    "##  CNN for detection\n",
    "\n",
    "- R-CNN\n",
    "- Fast R-CNN\n",
    "- Faster R-CNN\n",
    "- Mask R-CNN\n",
    "- YOLO\n",
    "- FCN\n",
    "- Hourglass\n",
    "- U-Net\n",
    "\n",
    "## \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
