{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f3a255-d258-4331-8c65-9c3dca011046",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "- to deal sequential data\n",
    "  - text\n",
    "  - audio\n",
    "- update information and use the information to get information\n",
    "  - memory\n",
    " \n",
    "- natural language processing.\n",
    "\n",
    "\n",
    "## motivation (Speech recognition)\n",
    "\n",
    "we want to transform the wave data of speech into text.\n",
    "\n",
    "**problem**\n",
    "\n",
    "- Input can be of variable size\n",
    "\n",
    "standard neural networks can only handle data of a fixed input size. \n",
    "\n",
    "- we need neural network that can handle the sequential data.\n",
    "\n",
    "\n",
    "## Inductive bias (pre assumption of data.)\n",
    "\n",
    "**reccurent inductive bias**\n",
    "\n",
    "- the seqential processing of the input\n",
    "  - input has order\n",
    "  - output has order\n",
    "  - hidden information has order\n",
    "  - use previous output, hidden information and input at the point to get next output and hidden information\n",
    "- no direct acess to the past tokens\n",
    "  - hidden memory\n",
    "  - accessible from next token\n",
    "- recursion\n",
    "  - the model apply the same function to the different input several times.\n",
    "\n",
    "## mathematical formula \n",
    "\n",
    "**input**\n",
    "\n",
    "- $x_{t}(0,1,2,...,t)$\n",
    "- or \n",
    "- $h_{-1}$\n",
    "\n",
    "**recusive output**\n",
    "- $h_{t} =  \\sigma(\\boldsymbol{W}^{T}_{h}[h_{t-1},x_t])$\n",
    "- $y_t = \\sigma(\\boldsymbol{W}^{T}_{y}h_t)$\n",
    "\n",
    "**output**\n",
    "\n",
    "- $y_{t}$ all or just the last one\n",
    "- \n",
    "- $h(t)$ and $y(t)$\n",
    "\n",
    "## BackPropagation Through Time (BPTT) \n",
    "\n",
    "- usual back propagation works\n",
    "\n",
    "\n",
    "**difficulity**\n",
    "\n",
    "- long horizontal propagation.\n",
    "  - vanishing / exploding gradients.\n",
    "  - large memory/ computational footprint.\n",
    " \n",
    "**solution**\n",
    "\n",
    "- naive\n",
    "  - skip connection between each rnn\n",
    "\n",
    "- memory network\n",
    "  - long short-term memory (LSTM)\n",
    "  - \n",
    "\n",
    "\n",
    "## Memory networks\n",
    "\n",
    "- LSTM\n",
    "- GRU\n",
    "- NTM\n",
    "- MemNN\n",
    "- DNC\n",
    "\n",
    "## Bi-directional RNNs\n",
    "\n",
    "- simple RNN\n",
    "  - uses information beforehand\n",
    " \n",
    "- bi-directional Rnn\n",
    "  - uses future information also as input.\n",
    " \n",
    "### seq2vec\n",
    "\n",
    "### vec2seq\n",
    "\n",
    "### seq2seq \n",
    "\n",
    "\n",
    "\n",
    "## Auto-regressive generative modeling.\n",
    "\n",
    "- RNN\n",
    "  - output becomes next input\n",
    "\n",
    "## hyper parameters\n",
    "\n",
    "**method**\n",
    "- grid search\n",
    "- random search\n",
    "- baysian optimizatoin\n",
    "- and\n",
    "- cross validation \n",
    "\n",
    "\n",
    "**hyper parameters**\n",
    "\n",
    "- activation function\n",
    "  - sigmoid\n",
    "    - 1 / ( 1 + exp( -x ) )\n",
    "  - tanh\n",
    "    - 2sigmoid(2x)-1\n",
    "    - ( exp( x ) - exp( -x ) ) / ( exp( x ) + exp( -x ) )\n",
    "- \n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
