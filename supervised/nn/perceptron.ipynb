{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c584d448-be8b-4ad2-8f13-e98fee61fde8",
   "metadata": {},
   "source": [
    "# perceptron\n",
    "\n",
    "perceptron is used for binary linear classifier.\n",
    "\n",
    "**Given**\n",
    "- dataset $\\{(\\boldsymbol{x}^{(1)}, t^{(1)}), ..., (\\boldsymbol{x}^{(N)}, t^{(N)})\\}$\n",
    "\n",
    "\n",
    "  $\\boldsymbol{x}^{(i)} \\in \\boldsymbol{R}^d$\n",
    "\n",
    "  =\n",
    "\n",
    "  $\\boldsymbol{x}^{(i)} = \\{x^{(1)}, x^{(2)}, ...., x^{(d)}\\}$\n",
    "\n",
    "  for all i, ( $1 \\leq i \\leq N)$\n",
    "-  $t^{(i)} \\in \\{ 0, 1\\}$\n",
    "\n",
    "\n",
    "**hyper parameter**\n",
    "\n",
    "\n",
    "- optimization algorithm (GD/SGD/mini-batch SGC etc) \n",
    "- learning rate ( the bigger, the faster but more likely to diverge / the smaller, the more preicise and more likely to converge but slower)\n",
    "- number of epochs \n",
    "- initial value of parameters (weights/bias)\n",
    "- activation function (usually \n",
    "\n",
    "**drawbacks**\n",
    "\n",
    "- when the data set is not linearily separable, perceptron algorithm will never converge.\n",
    "- result is not probabilstic. ( while logstic regression use sigmoid activation function to get probabilstic result)\n",
    "- it is hard to generalize to the case when class is greater than 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7501884-674b-4f88-b783-412b2397304d",
   "metadata": {},
   "source": [
    "# training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
