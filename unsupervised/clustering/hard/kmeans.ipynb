{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67425ff9-6498-4878-82bc-489033742219",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "# K means\n",
    "\n",
    "- unsupervised\n",
    "- hard clustering\n",
    "- non-parametric \n",
    "\n",
    "## advantage\n",
    "\n",
    "- scalable\n",
    "- flexible\n",
    "- simple\n",
    "- efficient\n",
    "\n",
    "## disadvantage.\n",
    "\n",
    "- assumues shperical clusters \n",
    "\n",
    "- non - convex loss function\n",
    "  - have to try multiple initialization\n",
    "  - non-local split-and-merge\n",
    "    - merge two nearby clusters and split a big cluster into two\n",
    "   \n",
    "- sensitive to the initializaton\n",
    "  - different initialization output differently\n",
    " \n",
    "  -  have to try multiple initialization and pick the best one.\n",
    "\n",
    "## assumption / inductive bias \n",
    "\n",
    "- check if the data\n",
    "  - Isotropic\n",
    "    - multiple well-separated clusters in 2D space.\n",
    "  - Anisotropic\n",
    "    - different variance\n",
    "    - in different direction.\n",
    "\n",
    "- members of the same cluster are close / similar to each other\n",
    "  - close in distance \n",
    "- members of different clusters are not similar\n",
    " - far in distance\n",
    "\n",
    "- spherical clusters\n",
    "\n",
    "- all of the clusters are the same shape\n",
    "\n",
    "- should have the same variance. \n",
    "\n",
    "\n",
    "-  assume data lives in a euclidean space??\n",
    "-  points are in a high-dimensional??????\n",
    "\n",
    "\n",
    "## metrics/ loss function\n",
    "\n",
    "- Uk(1<=k<=K) centroids\n",
    "- r(nk) - assingment\n",
    "  - in {0,1}\n",
    "  - shows if n the data is in class k\n",
    "\n",
    "### objective function\n",
    "\n",
    "- J = $\\sum^{N}_{n=1}\\sum^{K}_{k=1}r(nk)|| x_n - Uk||^2_2$\n",
    "  - non-convex (no guaranteed to convere to the global minimum)\n",
    "  - \n",
    " \n",
    "### Silhouette analysis\n",
    "\n",
    "- s(i) = $\\frac{b(i)-a(i)}{max(a(i),b(i))}$\n",
    "  - a(i) - mean distance to points in its own cluster\n",
    "  - b(i) - mean distance to points in nearest neighboring cluster\n",
    "  - is in [-1,1]\n",
    "- s(i) => 1 optimal clustering\n",
    "- s(i) => 0 the point lies between clusters\n",
    "- s(i) =>-1 the point is missclassified. \n",
    "\n",
    "\n",
    "## hyper parameter \n",
    "\n",
    "- the number of class - k\n",
    "  - \n",
    "\n",
    "- distance\n",
    "  - Euclidean\n",
    "  - Cosine\n",
    "  - Jaccard\n",
    "  - edit distance\n",
    "\n",
    "\n",
    "\n",
    "## data preprocessing before \n",
    "\n",
    "- scaling because algorithm uses distance.\n",
    "\n",
    "\n",
    "## algorithm \n",
    "\n",
    "- initialize the cluster centers\n",
    "  - randomly\n",
    "  - kmeans ++\n",
    "  - naive sharding\n",
    "- assign all the data to group based on the distance between cluster centers and each point\n",
    "- recalculate the cluster centers\n",
    "  - mean\n",
    "- check if the model have to update cluster centers\n",
    "  - converge or not.\n",
    " \n",
    "**Pesudo code**\n",
    "\n",
    "- initialze k centroids\n",
    "- repeat until convergence\n",
    "  - fix Uk and minimize based on r(nk)\n",
    "  - fix r(nk) and minimize based on Uk\n",
    "  - recalculate centroids\n",
    "    - mean\n",
    "\n",
    "## initializations \n",
    "\n",
    "### K-Means ++ \n",
    "\n",
    "- choose centroids one by one.\n",
    "  - first, choose one uniformly at random\n",
    "    - choose subsequent centroid\n",
    "    - get the distance from each point to the each centroids\n",
    "      - D(x) is the closest distance. \n",
    "    - choose next centroids with probability proportional to D(x)^2\n",
    "      - $p(x) = D(x)^2 / sum(D(x)^2)$\n",
    "    - normalize probabilies before selection. \n",
    "    \n",
    "\n",
    "### Percentile-based initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc3557-7a47-4008-9560-399ab2680a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, floor\n",
    "import numpy as np\n",
    "def random(ds, k, random_state=123):\n",
    "    np.random.seed(random_state=123):\n",
    "    \n",
    "centroids = []\n",
    "m = np.shape(ds)[0]\n",
    "for _ in range(k):\n",
    "r = np.random.randint(0, m-1)\n",
    "centroids.append(ds[r])\n",
    "return np.array(centroids)\n",
    "def plus_plus(ds, k, random_state=42):\n",
    "\"\"\"\n",
    "    Create cluster centroids using the k-means++ algorithm.\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : numpy array\n",
    "        The dataset to be used for centroid initialization.\n",
    "    k : int\n",
    "        The desired number of clusters for which centroids are required.\n",
    "    Returns\n",
    "    -------\n",
    "    centroids : numpy array\n",
    "        Collection of k centroids as a numpy array.\n",
    "    Inspiration from here: https://stackoverflow.com/questions/5466323/how-could-one-implement-the-k-means-algorithm\n",
    "    \"\"\"\n",
    "np.random.seed(random_state)\n",
    "centroids = [ds[0]]\n",
    "for _ in range(1, k):\n",
    "dist_sq = np.array([min([np.inner(c-x,c-x) for c in centroids]) for x in ds])\n",
    "probs = dist_sq/dist_sq.sum()\n",
    "cumulative_probs = probs.cumsum()\n",
    "r = np.random.rand()\n",
    "for j, p in enumerate(cumulative_probs):\n",
    "if r < p:\n",
    "i = j\n",
    "break\n",
    "centroids.append(ds[i])\n",
    "return np.array(centroids)\n",
    "def naive_sharding(ds, k):\n",
    "\"\"\"\n",
    "    Create cluster centroids using deterministic naive sharding algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : numpy array\n",
    "        The dataset to be used for centroid initialization.\n",
    "    k : int\n",
    "        The desired number of clusters for which centroids are required.\n",
    "    Returns\n",
    "    -------\n",
    "    centroids : numpy array\n",
    "        Collection of k centroids as a numpy array.\n",
    "    \"\"\"\n",
    "def _get_mean(sums, step):\n",
    "\"\"\"Vectorizable ufunc for getting means of summed shard columns.\"\"\"\n",
    "return sums/step\n",
    "n = np.shape(ds)[1]\n",
    "m = np.shape(ds)[0]\n",
    "centroids = np.zeros((k, n))\n",
    "composite = np.mat(np.sum(ds, axis=1))\n",
    "ds = np.append(composite.T, ds, axis=1)\n",
    "ds.sort(axis=0)\n",
    "step = floor(m/k)\n",
    "vfunc = np.vectorize(_get_mean)\n",
    "for j in range(k):\n",
    "if j == k-1:\n",
    "centroids[j:] = vfunc(np.sum(ds[j*step:,1:], axis=0), step)\n",
    "else:\n",
    "centroids[j:] = vfunc(np.sum(ds[j*step:(j+1)*step,1:], axis=0), step)\n",
    "return centroids\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
